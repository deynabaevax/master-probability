{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions data successfully written to actions-9aba6d6a38c6423da035ea1be76a3cd9-SDT_Mhf39t20241208_030645_FieldExperience_NXT.csv.\n",
      "Solutions data successfully written to solutions-9aba6d6a38c6423da035ea1be76a3cd9-SDT_Mhf39t20241208_030645_FieldExperience_NXT.csv.\n"
     ]
    }
   ],
   "source": [
    "# Version 1 without handling multiple AP versions\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "# Load the XML data\n",
    "xml_file_path = \"C:/Users/dbaeva/Documents/Docs/master-probability-causality/notebooks/case-2/data/field-feedback/SDT_Mhf39t20241030_050854_FieldExperience_NXT.xml\"\n",
    "\n",
    "# Parse the XML\n",
    "tree = ET.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Function to flatten XML elements\n",
    "def flatten_xml(element, parent_key=\"\", sep=\".\"):\n",
    "    \"\"\"Recursively flattens an XML element and its children.\"\"\"\n",
    "    items = {}\n",
    "    # Include attributes\n",
    "    for key, value in element.attrib.items():\n",
    "        items[f\"{parent_key}{sep}{key}\".strip(sep)] = value\n",
    "    # Include tag text separately\n",
    "    if element.text and element.text.strip():\n",
    "        items[f\"{parent_key}.text\".strip(sep)] = element.text.strip()\n",
    "    # Recurse into children\n",
    "    for child in element:\n",
    "        items.update(flatten_xml(child, f\"{parent_key}{sep}{child.tag}\".strip(sep), sep=sep))\n",
    "    return items\n",
    "\n",
    "# Prepare rows for actions and solutions\n",
    "actions = []\n",
    "solutions = []\n",
    "\n",
    "# Process each DdfActionPlan\n",
    "for plan in root.findall(\".//DdfActionPlan\"):\n",
    "    base_row = flatten_xml(plan)\n",
    "\n",
    "    # Extract nested actions\n",
    "    for action in plan.findall(\".//DdfActionList/DdfAction\"):\n",
    "        action_row = base_row.copy()\n",
    "        action_row.update(flatten_xml(action, \"DdfAction\"))\n",
    "        actions.append(action_row)\n",
    "\n",
    "    # Extract nested solutions\n",
    "    for solution in plan.findall(\".//DdfSolutionList/DdfSolution\"):\n",
    "        solution_row = base_row.copy()\n",
    "        solution_row.update(flatten_xml(solution, \"DdfSolution\"))\n",
    "        solutions.append(solution_row)\n",
    "\n",
    "# Write actions to a CSV file\n",
    "action_headers = sorted({key for row in actions for key in row.keys()})\n",
    "action_csv_file = \"C:/Users/dbaeva/Documents/Docs/master-probability-causality/notebooks/case-2/data/act-and-sol/actions-9aba6d6a38c6423da035ea1be76a3cd9-SDT_Mhf39t20241030_050854_FieldExperience_NXT.csv\"\n",
    "with open(action_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=action_headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(actions)\n",
    "print(f\"Actions data successfully written to {action_csv_file}.\")\n",
    "\n",
    "# Write solutions to a CSV file\n",
    "solution_headers = sorted({key for row in solutions for key in row.keys()})\n",
    "solution_csv_file = \"C:/Users/dbaeva/Documents/Docs/master-probability-causality/notebooks/case-2/data/act-and-sol/solutions-9aba6d6a38c6423da035ea1be76a3cd9-SDT_Mhf39t20241030_050854_FieldExperience_NXT.csv\"\n",
    "with open(solution_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=solution_headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(solutions)\n",
    "print(f\"Solutions data successfully written to {solution_csv_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2 with handling multiple AP versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ActionPlan version v1...\n",
      "  Extracted 6 actions and 7 solutions.\n",
      "  Actions for v1 written to act-and-sol/actions\\actions-SDT_M9905t20231019_083344_FieldExperience_NXT-v1.csv.\n",
      "  Solutions for v1 written to act-and-sol/solutions\\solutions-SDT_M9905t20231019_083344_FieldExperience_NXT-v1.csv.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Load the XML data\n",
    "xml_file_path = \"data/field-feedback/SDT_M9905t20231019_083344_FieldExperience_NXT.xml\"\n",
    "\n",
    "# Parse the XML\n",
    "tree = ET.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Function to flatten XML elements\n",
    "def flatten_xml(element, parent_key=\"\", sep=\".\"):\n",
    "    \"\"\"Recursively flattens an XML element and its children.\"\"\"\n",
    "    items = {}\n",
    "    # Include attributes\n",
    "    for key, value in element.attrib.items():\n",
    "        items[f\"{parent_key}{sep}{key}\".strip(sep)] = value\n",
    "    # Include tag text separately\n",
    "    if element.text and element.text.strip():\n",
    "        items[f\"{parent_key}.text\".strip(sep)] = element.text.strip()\n",
    "    # Recurse into children\n",
    "    for child in element:\n",
    "        items.update(flatten_xml(child, f\"{parent_key}{sep}{child.tag}\".strip(sep), sep=sep))\n",
    "    return items\n",
    "\n",
    "# Prepare rows for actions and solutions\n",
    "actions = []\n",
    "solutions = []\n",
    "\n",
    "# Counter for versions\n",
    "version_counter = 1\n",
    "\n",
    "# Locate the DdfActionPlanList and process each DdfActionPlan\n",
    "for plan in root.findall(\".//DdfActionPlanList/DdfActionPlan\"):\n",
    "    version_label = f\"v{version_counter}\"  # Label to distinguish versions\n",
    "    version_counter += 1\n",
    "\n",
    "    # Extract actions and solutions for the current version\n",
    "    actions_version = []\n",
    "    solutions_version = []\n",
    "\n",
    "    base_row = flatten_xml(plan)\n",
    "\n",
    "    # Extract nested actions\n",
    "    for action in plan.findall(\".//DdfActionList/DdfAction\"):\n",
    "        action_row = base_row.copy()\n",
    "        action_row.update(flatten_xml(action, \"DdfAction\"))\n",
    "        actions_version.append(action_row)\n",
    "\n",
    "    # Extract nested solutions\n",
    "    for solution in plan.findall(\".//DdfSolutionList/DdfSolution\"):\n",
    "        solution_row = base_row.copy()\n",
    "        solution_row.update(flatten_xml(solution, \"DdfSolution\"))\n",
    "        solutions_version.append(solution_row)\n",
    "\n",
    "    # Debug: Print extracted counts\n",
    "    print(f\"Processing ActionPlan version {version_label}...\")\n",
    "    print(f\"  Extracted {len(actions_version)} actions and {len(solutions_version)} solutions.\")\n",
    "\n",
    "    # Write version-specific files\n",
    "    base_filename = os.path.splitext(os.path.basename(xml_file_path))[0]\n",
    "    actions_folder = \"act-and-sol/actions\"\n",
    "    solutions_folder = \"act-and-sol/solutions\"\n",
    "    os.makedirs(actions_folder, exist_ok=True)\n",
    "    os.makedirs(solutions_folder, exist_ok=True)\n",
    "\n",
    "    # Write actions for this version\n",
    "    if actions_version:\n",
    "        action_headers = sorted({key for row in actions_version for key in row.keys()})\n",
    "        action_csv_file = os.path.join(actions_folder, f\"actions-{base_filename}-{version_label}.csv\")\n",
    "        with open(action_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=action_headers)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(actions_version)\n",
    "        print(f\"  Actions for {version_label} written to {action_csv_file}.\")\n",
    "    else:\n",
    "        print(f\"  No actions to write for version {version_label}.\")\n",
    "\n",
    "    # Write solutions for this version\n",
    "    if solutions_version:\n",
    "        solution_headers = sorted({key for row in solutions_version for key in row.keys()})\n",
    "        solution_csv_file = os.path.join(solutions_folder, f\"solutions-{base_filename}-{version_label}.csv\")\n",
    "        with open(solution_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=solution_headers)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(solutions_version)\n",
    "        print(f\"  Solutions for {version_label} written to {solution_csv_file}.\")\n",
    "    else:\n",
    "        print(f\"  No solutions to write for version {version_label}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
