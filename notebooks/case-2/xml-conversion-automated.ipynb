{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to automate the process for extracting the needed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "# Define paths and DDF UUID\n",
    "shared_drive_path = r\"path_to_shared_drive\"\n",
    "ddf_uuid = \"9aba6d6a38c6423da035ea1be76a3cd9\"\n",
    "output_actions_dir = \"path_to_output/actions\"\n",
    "output_solutions_dir = \"path_to_output/solutions\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(output_actions_dir, exist_ok=True)\n",
    "os.makedirs(output_solutions_dir, exist_ok=True)\n",
    "\n",
    "# Function to flatten XML elements\n",
    "def flatten_xml(element, parent_key=\"\", sep=\".\"):\n",
    "    \"\"\"Recursively flattens an XML element and its children.\"\"\"\n",
    "    items = {}\n",
    "    for key, value in element.attrib.items():\n",
    "        items[f\"{parent_key}{sep}{key}\".strip(sep)] = value\n",
    "    if element.text and element.text.strip():\n",
    "        items[f\"{parent_key}.text\".strip(sep)] = element.text.strip()\n",
    "    for child in element:\n",
    "        items.update(flatten_xml(child, f\"{parent_key}{sep}{child.tag}\".strip(sep), sep=sep))\n",
    "    return items\n",
    "\n",
    "# Function to process a single XML file\n",
    "def process_xml_file(xml_file):\n",
    "    try:\n",
    "        # Parse the XML\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Check if DDF UUID exists in the file\n",
    "        if not any(ddf_uuid in elem.text for elem in root.findall(\".//DDF_GUID\")):\n",
    "            return False  # Skip files without the target DDF UUID\n",
    "        \n",
    "        actions = []\n",
    "        solutions = []\n",
    "        \n",
    "        # Process each DdfActionPlan\n",
    "        for plan in root.findall(\".//DdfActionPlan\"):\n",
    "            base_row = flatten_xml(plan)\n",
    "\n",
    "            # Extract nested actions\n",
    "            for action in plan.findall(\".//DdfActionList/DdfAction\"):\n",
    "                action_row = base_row.copy()\n",
    "                action_row.update(flatten_xml(action, \"DdfAction\"))\n",
    "                actions.append(action_row)\n",
    "\n",
    "            # Extract nested solutions\n",
    "            for solution in plan.findall(\".//DdfSolutionList/DdfSolution\"):\n",
    "                solution_row = base_row.copy()\n",
    "                solution_row.update(flatten_xml(solution, \"DdfSolution\"))\n",
    "                solutions.append(solution_row)\n",
    "        \n",
    "        # Write actions to CSV\n",
    "        if actions:\n",
    "            action_headers = sorted({key for row in actions for key in row.keys()})\n",
    "            action_csv_file = os.path.join(output_actions_dir, f\"actions-{ddf_uuid}-{os.path.basename(xml_file)}.csv\")\n",
    "            with open(action_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=action_headers)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(actions)\n",
    "            print(f\"Actions data written to {action_csv_file}\")\n",
    "\n",
    "        # Write solutions to CSV\n",
    "        if solutions:\n",
    "            solution_headers = sorted({key for row in solutions for key in row.keys()})\n",
    "            solution_csv_file = os.path.join(output_solutions_dir, f\"solutions-{ddf_uuid}-{os.path.basename(xml_file)}.csv\")\n",
    "            with open(solution_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=solution_headers)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(solutions)\n",
    "            print(f\"Solutions data written to {solution_csv_file}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {xml_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main script to process all XML files in the shared drive\n",
    "for root_dir, dirs, files in os.walk(shared_drive_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".xml\"):\n",
    "            file_path = os.path.join(root_dir, file)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            if process_xml_file(file_path):\n",
    "                print(f\"File {file_path} processed successfully.\")\n",
    "            else:\n",
    "                print(f\"File {file_path} skipped (DDF UUID not found).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
